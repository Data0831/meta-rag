import tiktoken
from typing import List

class UnifiedTokenSplitter:
    def __init__(self, model_name: str = "gpt-4o", chunk_size: int = 1500, overlap: int = 300, tolerance: int = 200):
        """
        åˆå§‹åŒ–åƒæ•¸ï¼š
        :param chunk_size: ç›®æ¨™åˆ‡å¡Šå¤§å° (ä¾‹å¦‚ 1500)
        :param overlap: é‡ç–Šå¤§å° (ä¾‹å¦‚ 300)
        :param tolerance: ğŸ”¥ [æ–°å¢] å®¹è¨±æº¢å‡ºçš„ç·©è¡å€ (ä¾‹å¦‚ 200)
                          å¦‚æœå‰©é¤˜ token æ•¸ < chunk_size + toleranceï¼Œå°±ä¸å†åˆ‡åˆ†ã€‚
        """
        self.chunk_size = chunk_size
        self.overlap = overlap
        self.tolerance = tolerance  # æ–°å¢å®¹è¨±å€¼
        
        try:
            self.enc = tiktoken.encoding_for_model(model_name)
        except:
            self.enc = tiktoken.get_encoding("cl100k_base")

        self.separators = ["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", ". ", "! ", "? ", "ï¼›", ";", "ï¼Œ", ","]

    def count_tokens(self, text: str) -> int:
        if not text: return 0
        return len(self.enc.encode(text))

    def split_text(self, text: str) -> List[str]:
        # ğŸ”¥ [ä¿®æ”¹ 1] é ‚å±¤åˆ¤æ–·ï¼šå¦‚æœç¸½é•·åº¦åœ¨ (1500 + 200) ä»¥å…§ï¼Œç›´æ¥å›å‚³
        if self.count_tokens(text) <= (self.chunk_size + self.tolerance):
            return [text]

        chunks = []
        self._recursive_split(text, chunks)
        return chunks

    def _recursive_split(self, text: str, chunks: List[str]):
        # ğŸ”¥ [ä¿®æ”¹ 2] éè¿´çµ‚æ­¢æ¢ä»¶ï¼šåŒ…å«å®¹è¨±å€¼
        # å‡è¨­å‰©é¤˜æ–‡å­—æ˜¯ 1600 tokensï¼Œå› ç‚º <= 1700ï¼Œæ‰€ä»¥é€™è£¡å°±æœƒåœæ­¢éè¿´ï¼Œç›´æ¥ä¿ç•™
        if self.count_tokens(text) <= (self.chunk_size + self.tolerance):
            if text.strip():
                chunks.append(text)
            return

        # --- ä»¥ä¸‹é‚è¼¯ä¿æŒä¸è®Šï¼Œè² è²¬è™•ç†çœŸçš„å¤ªé•·çš„æƒ…æ³ ---
        
        token_integers = self.enc.encode(text)
        limit_tokens = token_integers[:self.chunk_size] # é€™è£¡ä¾ç„¶ç”¨ 1500 ä¾†å®šä½åˆ‡é»
        hard_limit_char_index = len(self.enc.decode(limit_tokens))

        best_split_index = -1
        for sep in self.separators:
            found_idx = text.rfind(sep, 0, hard_limit_char_index)
            if found_idx != -1:
                best_split_index = found_idx + len(sep)
                break
        
        if best_split_index == -1:
            best_split_index = hard_limit_char_index

        current_chunk = text[:best_split_index]
        chunks.append(current_chunk)

        overlap_token_count = min(self.overlap, len(limit_tokens))
        tokens_before_split = self.enc.encode(current_chunk)
        overlap_tokens_ids = tokens_before_split[-overlap_token_count:]
        overlap_char_len = len(self.enc.decode(overlap_tokens_ids))
        
        next_start_index = max(0, best_split_index - overlap_char_len)

        if next_start_index >= len(text) - 10: return 
        if next_start_index <= 0 and len(chunks) > 0: next_start_index = best_split_index 

        remaining_text = text[next_start_index:]
        self._recursive_split(remaining_text, chunks)