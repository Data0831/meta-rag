sequenceDiagram
    participant Agent as srhSumAgent.py
    participant LLM as LLMClient
    participant Reranker as ResultReranker
    participant Meili as Meilisearch

    Agent->>search_service.py: search(query, limit, semantic_ratio, history, direction, exclude_ids...)

    rect rgb(255, 250, 240)
        Note over search_service.py,LLM: 1. Query Rewrite - æ„åœ–è§£æèˆ‡æŸ¥è©¢æ”¹å¯«
        search_service.py->>LLM: (query, history, direction, website)
        Note over LLM: Prompt åŒ…å«:<br>- ç•¶å‰æ—¥æœŸ<br>- æ­·å²æŸ¥è©¢<br>- AI å„ªåŒ–æ–¹å‘<br>- æŒ‡å®šç¶²ç«™ä¾†æº
        LLM-->>search_service.py: SearchIntent {<br>  keyword_query: "æ”¹å¯«å¾Œé—œéµå­—",<br>  semantic_query: "èªç¾©æŸ¥è©¢",<br>  sub_queries: ["å­æŸ¥è©¢1", "å­æŸ¥è©¢2"],<br>  must_have_keywords: ["é—œéµè©"],<br>  year_month: ["2025-12"],<br>  recommended_semantic_ratio: 0.8<br>}
        
        alt LLM è§£æå¤±æ•—
            search_service.py->>search_service.py: Fallback ä½¿ç”¨åŸå§‹ query
        end
    end

    rect rgb(240, 255, 245)
        Note over search_service.py: 3ï¸âƒ£ å»ºæ§‹æŸ¥è©¢å€™é¸é›† (å¹³è¡Œå­æŸ¥è©¢)
        search_service.py->>search_service.py: _build_query_candidates(intent)
        Note over search_service.py: çµ„åˆæŸ¥è©¢åˆ—è¡¨:<br>1. Primary: keyword_query<br>2. Sub-Query 1<br>3. Sub-Query 2<br>...
    end

    rect rgb(255, 245, 250)
        Note over search_service.py: 4ï¸âƒ£ å»ºæ§‹éæ¿¾æ¢ä»¶
        search_service.py->>search_service.py: _build_filter_expression(intent, dates, exclude_ids, website)
        Note over search_service.py: çµ„åˆ Meilisearch Filter:<br>- AI æ—¥æœŸ OR æ‰‹å‹•æ—¥æœŸç¯„åœ<br>- æŒ‡å®šç¶²ç«™ä¾†æº<br>- æ’é™¤å·²è¦‹ ID (exclude_ids)
    end

    rect rgb(245, 250, 255)
        Note over search_service.py,Meili: 5ï¸âƒ£ å¹³è¡Œå­æŸ¥è©¢åŸ·è¡Œ (Multi-Search)
        
        loop ç‚ºæ¯å€‹æŸ¥è©¢å€™é¸å»ºæ§‹åƒæ•¸
            search_service.py->>search_service.py: _build_single_query_params(query_text, intent, semantic_ratio)
            
            alt semantic_ratio > 0 (æ··åˆæª¢ç´¢)
                search_service.py->>search_service.py: get_embedding(semantic_query)
                Note over search_service.py: ç”Ÿæˆå‘é‡è¡¨ç¤º
            end
            
            Note over search_service.py: å»ºæ§‹æœå°‹åƒæ•¸:<br>{<br>  q: "keyword_query",<br>  limit: pre_search_limit * 1.5 (if retry),<br>  filter: "year_month >= 2025-10 AND...",<br>  hybrid: { semanticRatio: 0.8 },<br>  vector: [0.123, 0.456, ...]<br>}
        end
        
        search_service.py->>Meili: multi_search([query1_params, query2_params, ...])
        
        Note over Meili: ğŸ” Meilisearch æ··åˆæª¢ç´¢å¼•æ“
        
        par å¹³è¡ŒåŸ·è¡Œå¤šå€‹æŸ¥è©¢
            rect rgb(255, 255, 240)
                Note over Meili: Query 1: Primary Keyword
                Meili->>Meili: æ¨¡ç³ŠåŒ¹é… (Fuzzy Match)<br>- éŒ¯å­—å®¹å¿<br>- å‰ç¶´æœå°‹<br>- åŒç¾©è©æ“´å±•
                Meili->>Meili: èªç¾©åŒ¹é… (Semantic Search)<br>- å‘é‡ç›¸ä¼¼åº¦è¨ˆç®—<br>- æ¦‚å¿µç†è§£
                Meili->>Meili: å¥—ç”¨éæ¿¾å™¨ (Filters)<br>- æ—¥æœŸç¯„åœ<br>- ç¶²ç«™ä¾†æº<br>- æ’é™¤ ID
                Meili->>Meili: æ··åˆæ’åº<br>Score = (1-ratio)*keyword + ratio*semantic
            end
        and
            rect rgb(240, 255, 255)
                Note over Meili: Query 2: Sub-Query 1
                Meili->>Meili: åŒä¸Šæ··åˆæª¢ç´¢æµç¨‹
            end
        and
            rect rgb(255, 240, 255)
                Note over Meili: Query 3: Sub-Query 2
                Meili->>Meili: åŒä¸Šæ··åˆæª¢ç´¢æµç¨‹
            end
        end
        
        Meili-->>search_service.py: è¿”å›æ‰¹æ¬¡çµæœ {<br>  results: [<br>    { hits: [...], estimatedTotalHits: 100 },<br>    { hits: [...], estimatedTotalHits: 85 },<br>    ...<br>  ]<br>}
    end

    rect rgb(250, 245, 255)
        Note over search_service.py: 6ï¸âƒ£ è·¨æŸ¥è©¢å»é‡
        search_service.py->>search_service.py: _deduplicate_hits(raw_hits_batch)
        Note over search_service.py: åˆä½µæ‰€æœ‰å­æŸ¥è©¢çµæœ<br>æŒ‰ document ID å»é‡<br>ä¿ç•™é¦–æ¬¡å‡ºç¾çš„æ–‡æª”
    end

    rect rgb(255, 250, 245)
        Note over search_service.py,Reranker: 7ï¸âƒ£ é—œéµå­—åŠ æ¬Šé‡æ’ (Keyword Reranking)
        search_service.py->>Reranker: ResultReranker(all_hits, must_have_keywords)
        search_service.py->>Reranker: rerank(top_k = limit * 2.5)
        
        loop éæ­·æ¯å€‹æ–‡æª”
            Reranker->>Reranker: æª¢æŸ¥é—œéµå­—å‘½ä¸­
            Note over Reranker: æ¨™é¡Œ + å…§å®¹ä¸­<br>æª¢æŸ¥ must_have_keywords<br>è¨ˆç®—å‘½ä¸­æ¯”ä¾‹ (hit_ratio)
            
            Reranker->>Reranker: è¨ˆç®—åŠ æ¬Šåˆ†æ•¸
            Note over Reranker: å…¬å¼:<br>penalty = original * (1 - P*(1-ratio))<br>boost = B * ratio * (1-original)<br>final_score = penalty + boost<br><br>P = 0.25 (æ‡²ç½°ä¿‚æ•¸)<br>B = 0.55 (æå‡ä¿‚æ•¸)
        end
        
        Reranker->>Reranker: æŒ‰ _rerank_score é™åºæ’åº
        Reranker-->>search_service.py: è¿”å›é‡æ’å¾Œçµæœ (top_k ç­†)
    end

    rect rgb(245, 255, 250)
        Note over search_service.py: 8ï¸âƒ£ Link å»é‡åˆä½µ
        search_service.py->>search_service.py: _merge_duplicate_links(reranked_results)
        
        loop éæ­·é‡æ’çµæœ
            alt ç›¸åŒ Link å·²å­˜åœ¨
                search_service.py->>search_service.py: åˆä½µ content (ç”¨ \n---\n åˆ†éš”)
                search_service.py->>search_service.py: åˆä½µ all_ids åˆ—è¡¨
                search_service.py->>search_service.py: ç´¯åŠ  token è¨ˆæ•¸
                Note over search_service.py: ä¿ç•™æœ€é«˜åˆ†æ–‡æª”çš„ metadata
            else æ–° Link
                search_service.py->>search_service.py: åŠ å…¥çµæœåˆ—è¡¨
            end
        end
        
        search_service.py->>search_service.py: æˆªå–å‰ limit ç­†
    end

    rect rgb(250, 250, 250)
        Note over search_service.py: 9ï¸âƒ£ å»ºæ§‹å›æ‡‰
        search_service.py->>search_service.py: _build_response(intent, results, traces)
    end

    search_service.py-->>Agent: è¿”å›æœå°‹çµæœ {<br>  status: "success",<br>  intent: {...},<br>  results: [...],<br>  final_semantic_ratio: 0.8,<br>  mode: "semantic",<br>  traces: [...]<br>}

